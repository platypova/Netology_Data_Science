{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\"¶\n",
    "## Задание 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обязательная часть\n",
    "Будем парсить страницу со свежеми новостям на habr.com/ru/all/.  \n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:  \n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']  \n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).  \n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['python', 'парсинг','программировать','архитектура','технологий','платформа']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем страницу с самыми свежими постами\n",
    "req = requests.get('https://habr.com/ru/all/')\n",
    "soup = BeautifulSoup(req.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# извлекаем статьи\n",
    "articles = soup.find_all('article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ArticlesData = pd.DataFrame(columns = {'Date','Title','Link'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(title_element, article_time):\n",
    "    \n",
    "    title_text = title_element.text\n",
    "    article_link = title_element.attrs.get('href')\n",
    "    \n",
    "    if 'сегодня' in article_time.split(' '):\n",
    "        article_date = datetime.date.today()\n",
    "    elif 'вчера' in article_time.split(' '):\n",
    "        yesterday = datetime.datetime.now() - datetime.timedelta(1)\n",
    "        article_date = yesterday.date()\n",
    "    else:\n",
    "        article_date = article_time\n",
    "    \n",
    "    return title_text, article_link, article_date\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artcl in articles:\n",
    "    \n",
    "    title_element = artcl.find('a', class_='post__title_link')\n",
    "    artcl_element_0 = artcl.find('div', class_='post__text_v1')\n",
    "    artcl_element_1 = artcl.find('div', class_='post__text_v2')\n",
    "\n",
    "    for keyword in KEYWORDS:\n",
    "        if title_element:\n",
    "            if keyword in title_element.text:\n",
    "                title_text, article_link, article_date = get_data(title_element,artcl.find('span', class_='post__time').text)\n",
    "                article_data_sample = {'Date':article_date,'Title':title_text,'Link':article_link}\n",
    "                ArticlesData = ArticlesData.append(article_data_sample, ignore_index=True)\n",
    "                \n",
    "            elif artcl_element_0:\n",
    "                if keyword in artcl_element_0.text:\n",
    "                    title_text, article_link, article_date = get_data(title_element,artcl.find('span', class_='post__time').text)\n",
    "                    article_data_sample = {'Date':article_date,'Title':title_text,'Link':article_link}\n",
    "                    ArticlesData = ArticlesData.append(article_data_sample, ignore_index=True)\n",
    "                    \n",
    "            elif artcl_element_1:\n",
    "                if keyword in artcl_element_1.text:\n",
    "                    title_text, article_link, article_date = get_data(title_element,artcl.find('span', class_='post__time').text)\n",
    "                    article_data_sample = {'Date':article_date,'Title':title_text,'Link':article_link}\n",
    "                    ArticlesData = ArticlesData.append(article_data_sample, ignore_index=True)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Создаем Booking приложение с Webix UI</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>https://habr.com/ru/post/551988/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Title        Date  \\\n",
       "0  Создаем Booking приложение с Webix UI  2021-04-12   \n",
       "\n",
       "                               Link  \n",
       "0  https://habr.com/ru/post/551988/  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ArticlesData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]  \n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>  \n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы.  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL = ['xxx@x.ru', 'yyy@y.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWSFEED_REQUEST = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Vaar-Version': '0',\n",
    "    'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
    "    'Vaar-Header-App-Product-Name': 'hackcheck-web-avast',\n",
    "    'Vaar-Header-App-Build-Version': '1.0.0'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeakageData = pd.DataFrame(columns = {'email','date','source','description'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for email in EMAIL:\n",
    "    res = requests.post(NEWSFEED_REQUEST, json={'emailAddresses': [email]},headers = params)\n",
    "    extracted_data = json.loads(res.text) \n",
    "    if extracted_data:\n",
    "        for key in extracted_data['breaches'].keys():\n",
    "            description = extracted_data['breaches'][key]['description']\n",
    "            date = extracted_data['breaches'][key]['publishDate']\n",
    "            source = extracted_data['breaches'][key]['site']\n",
    "            site = extracted_data['breaches'][key]['site']\n",
    "            data_sample = {'email':email,'date':date,'source':source,'description':description}\n",
    "            LeakageData = LeakageData.append(data_sample,ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>date</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In July and August 2016, two criminals execute...</td>\n",
       "      <td>parapa.mail.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "      <td>cfire.mail.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In March 2016, CDProjektRed.com.com's forum da...</td>\n",
       "      <td>cdprojektred.com</td>\n",
       "      <td>2017-01-31T00:00:00Z</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>xxx@x.ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>At an unconfirmed date, online Arizona newspap...</td>\n",
       "      <td>azcentral.com</td>\n",
       "      <td>2020-01-03T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In January 2020, the online poll website Wishb...</td>\n",
       "      <td>wishbone.io</td>\n",
       "      <td>2020-05-28T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In October 2017, a customer database belonging...</td>\n",
       "      <td>myheritage.com</td>\n",
       "      <td>2017-11-04T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>At an unconfirmed date, the Russian-language m...</td>\n",
       "      <td>forums.vkmonline.com</td>\n",
       "      <td>2021-02-11T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>In May 2019, graphic-design site Canva's datab...</td>\n",
       "      <td>canva.com</td>\n",
       "      <td>2019-06-13T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "      <td>dropbox.com</td>\n",
       "      <td>2016-10-24T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In 2012, online professional networking platfo...</td>\n",
       "      <td>linkedin.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>On an unconfirmed date, Chinese gossip site Ra...</td>\n",
       "      <td>rayli.com.cn</td>\n",
       "      <td>2017-03-01T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>In September 2019, the game developer Zynga wa...</td>\n",
       "      <td>zynga.com</td>\n",
       "      <td>2019-10-17T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Netlog (formerly known as Facebox and Bingbox)...</td>\n",
       "      <td>netlog.com</td>\n",
       "      <td>2018-02-18T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>In 2016, Global Reach Technology's database wa...</td>\n",
       "      <td>globalreach.eu</td>\n",
       "      <td>2017-03-15T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Youku is a large Chinese video content company...</td>\n",
       "      <td>youku.com</td>\n",
       "      <td>2017-03-24T00:00:00Z</td>\n",
       "      <td>yyy@y.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          description                source  \\\n",
       "0   In July and August 2016, two criminals execute...        parapa.mail.ru   \n",
       "1   Popular Russian social networking platform VKo...                vk.com   \n",
       "2   In October of 2013, criminals penetrated Adobe...             adobe.com   \n",
       "3   In July and August of 2016, two criminals carr...         cfire.mail.ru   \n",
       "4   In March 2016, CDProjektRed.com.com's forum da...      cdprojektred.com   \n",
       "5   In June 2016, a cache of over 51 million user ...             imesh.com   \n",
       "6   At an unconfirmed date, online Arizona newspap...         azcentral.com   \n",
       "7   In January 2020, the online poll website Wishb...           wishbone.io   \n",
       "8   In October 2017, a customer database belonging...        myheritage.com   \n",
       "9   At an unconfirmed date, the Russian-language m...  forums.vkmonline.com   \n",
       "10  In May 2019, graphic-design site Canva's datab...             canva.com   \n",
       "11  Cloud storage company Dropbox suffered a major...           dropbox.com   \n",
       "12  In 2012, online professional networking platfo...          linkedin.com   \n",
       "13  On an unconfirmed date, Chinese gossip site Ra...          rayli.com.cn   \n",
       "14  In September 2019, the game developer Zynga wa...             zynga.com   \n",
       "15  In October of 2013, criminals penetrated Adobe...             adobe.com   \n",
       "16  Netlog (formerly known as Facebox and Bingbox)...            netlog.com   \n",
       "17  In 2016, Global Reach Technology's database wa...        globalreach.eu   \n",
       "18  In June 2016, a cache of over 51 million user ...             imesh.com   \n",
       "19  Youku is a large Chinese video content company...             youku.com   \n",
       "\n",
       "                    date      email  \n",
       "0   2017-02-14T00:00:00Z   xxx@x.ru  \n",
       "1   2016-10-29T00:00:00Z   xxx@x.ru  \n",
       "2   2016-10-21T00:00:00Z   xxx@x.ru  \n",
       "3   2017-02-14T00:00:00Z   xxx@x.ru  \n",
       "4   2017-01-31T00:00:00Z   xxx@x.ru  \n",
       "5   2016-10-23T00:00:00Z   xxx@x.ru  \n",
       "6   2020-01-03T00:00:00Z  yyy@y.com  \n",
       "7   2020-05-28T00:00:00Z  yyy@y.com  \n",
       "8   2017-11-04T00:00:00Z  yyy@y.com  \n",
       "9   2021-02-11T00:00:00Z  yyy@y.com  \n",
       "10  2019-06-13T00:00:00Z  yyy@y.com  \n",
       "11  2016-10-24T00:00:00Z  yyy@y.com  \n",
       "12  2016-10-21T00:00:00Z  yyy@y.com  \n",
       "13  2017-03-01T00:00:00Z  yyy@y.com  \n",
       "14  2019-10-17T00:00:00Z  yyy@y.com  \n",
       "15  2016-10-21T00:00:00Z  yyy@y.com  \n",
       "16  2018-02-18T00:00:00Z  yyy@y.com  \n",
       "17  2017-03-15T00:00:00Z  yyy@y.com  \n",
       "18  2016-10-23T00:00:00Z  yyy@y.com  \n",
       "19  2017-03-24T00:00:00Z  yyy@y.com  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeakageData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
